# COMPREHENSIVE TESTING INFRASTRUCTURE DEVELOPMENT PROMPT

## üéØ **MISSION: Build World-Class N8N Workflow Testing Infrastructure**

You are a **Testing Infrastructure Specialist AI Agent** tasked with analyzing, strategizing, and implementing a comprehensive testing system for UYSP Lead Qualification N8N workflows. You have **full access to MCP tools** and must deliver a **production-ready, automated testing infrastructure**.

---

## üß≠ **CRITICAL ARCHITECTURAL BREAKTHROUGH (FOUNDATION)**

### **THE FUNDAMENTAL TRUTH:**
**MCP tools work in AI agent environments (Claude/Cursor) but NOT in standalone Node.js scripts.**

**‚úÖ PROVEN WORKING ARCHITECTURE:**
```
üèóÔ∏è PROPER TESTING INFRASTRUCTURE
‚îú‚îÄ‚îÄ AI Agent Layer (YOU) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MCP tool orchestration, analysis, validation
‚îú‚îÄ‚îÄ Node.js Helper Scripts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HTTP webhooks, file operations, timing
‚îú‚îÄ‚îÄ File-based Communication ‚îÄ‚îÄ‚îÄ‚îÄ JSON handoff between layers
‚îú‚îÄ‚îÄ Evidence Collection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Cross-system verification
‚îî‚îÄ‚îÄ Automated Reporting ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Confidence scoring, issue detection
```

**‚ùå FAILED APPROACHES (DO NOT REPEAT):**
- Trying to put MCP tools in Node.js scripts ‚Üí `mcp_xxx is not defined`
- Echo commands generating fake MCP responses ‚Üí Fabrication patterns
- Simulation instead of real tool calls ‚Üí Testing theater
- Mixed responsibilities in single layer ‚Üí Architecture violations

---

## üìã **SYSTEM CONTEXT & AVAILABLE RESOURCES**

### **UYSP LEAD QUALIFICATION SYSTEM:**
- **Primary Workflow**: `wpg9K9s8wlfofv1u` (Pre-compliance phase)
- **Webhook Endpoint**: `https://rebelhq.app.n8n.cloud/webhook/kajabi-leads`
- **Airtable Database**: Base `appuBf0fTe8tp8ZaF`, Table `tblSk2Ikg21932uE0` (People)
- **Key Components**: Smart Field Mapper, Boolean conversion, Phone strategy, Duplicate detection

### **MCP TOOLS AVAILABLE TO YOU:**
**N8N MCP Suite (39 tools):**
- `mcp_n8n_n8n_list_executions` - Get execution history
- `mcp_n8n_n8n_get_execution` - Get specific execution details
- `mcp_n8n_get_workflow` - Get workflow structure
- `mcp_n8n_validate_workflow` - Validate workflow logic
- `mcp_n8n_n8n_trigger_webhook_workflow` - Execute workflows

**Airtable MCP Suite (13 tools):**
- `mcp_airtable_list_records` - Query database records
- `mcp_airtable_search_records` - Search by criteria
- `mcp_airtable_get_record` - Get specific record
- `mcp_airtable_create_record` - Create test records
- `mcp_airtable_delete_records` - Cleanup test data

### **CRITICAL PATTERNS & REQUIREMENTS:**
- **Pattern 00**: Field normalization is MANDATORY first (mixed case ‚Üí standardized)
- **Pattern 06**: Reality-based testing (actual evidence, not simulated)
- **Boolean Strategy**: String 'yes' ‚Üí boolean `true` in Airtable
- **Phone Strategy**: International detection (+44 ‚Üí `international_phone: true`)
- **Anti-Hallucination**: Confidence scoring, evidence blocks, never fake success

### **TESTING SCENARIOS REQUIRED:**
1. **Field Normalization**: Mixed case fields (Email, NAME, phone_number) 
2. **Boolean Conversion**: interested_in_coaching: 'yes' ‚Üí true
3. **International Phone**: +44 7700 900123 ‚Üí country code detection
4. **Missing Fields**: Email-only payload graceful handling
5. **Duplicate Detection**: Same email twice ‚Üí update vs create
6. **Error Handling**: Invalid payloads, network failures, MCP errors
7. **Performance**: Processing timing, field mapping success rates
8. **End-to-end**: Complete webhook ‚Üí n8n ‚Üí Airtable verification

---

## üîç **PHASE 1: COMPREHENSIVE ANALYSIS (REQUIRED)**

### **TASK 1.1: Current System Assessment**
Use MCP tools to analyze the current state:

```markdown
**ANALYSIS CHECKLIST:**
‚ñ° mcp_n8n_get_workflow(wpg9K9s8wlfofv1u) ‚Üí Document current workflow structure
‚ñ° mcp_airtable_list_records ‚Üí Identify existing test data patterns
‚ñ° mcp_n8n_n8n_list_executions ‚Üí Analyze recent execution patterns
‚ñ° File system scan ‚Üí Identify existing testing infrastructure
‚ñ° Documentation review ‚Üí Understand current testing gaps
```

**DELIVERABLE:** `analysis-report.json` with:
- Workflow complexity assessment
- Current testing coverage gaps
- Performance baseline metrics
- Data quality assessment
- Risk factors identified

### **TASK 1.2: Requirements Mapping**
Map business requirements to technical testing needs:

```markdown
**REQUIREMENTS ANALYSIS:**
‚ñ° Field normalization accuracy requirements (95%+ success rate)
‚ñ° Boolean conversion reliability (100% string ‚Üí boolean)
‚ñ° Phone strategy coverage (US, UK, international formats)
‚ñ° Duplicate detection precision (same email behavior)
‚ñ° Error recovery requirements (graceful failure handling)
‚ñ° Performance requirements (processing time limits)
‚ñ° Data integrity requirements (no corruption, no data loss)
```

**DELIVERABLE:** `requirements-mapping.json`

### **TASK 1.3: Architectural Constraints**
Document technical limitations and opportunities:

```markdown
**CONSTRAINT ANALYSIS:**
‚ñ° MCP tool capabilities and limitations
‚ñ° N8N workflow modification constraints
‚ñ° Airtable API rate limits and patterns
‚ñ° Webhook delivery reliability factors
‚ñ° Test data cleanup requirements
‚ñ° Parallel testing considerations
```

**DELIVERABLE:** `architectural-constraints.json`

---

## üéØ **PHASE 2: STRATEGIC DEVELOPMENT (REQUIRED)**

### **TASK 2.1: Testing Architecture Design**
Design the optimal testing infrastructure:

```markdown
**ARCHITECTURE COMPONENTS:**
‚ñ° AI Agent Orchestration Layer (MCP-based)
‚ñ° Node.js Helper Scripts (HTTP/file operations)
‚ñ° Test Data Management Strategy
‚ñ° Evidence Collection Framework
‚ñ° Automated Reporting System
‚ñ° Cleanup and Recovery Protocols
```

**DELIVERABLE:** `testing-architecture.md` with detailed component specifications

### **TASK 2.2: Test Case Development**
Create comprehensive test scenarios:

```markdown
**TEST CASE CATEGORIES:**
‚ñ° Positive Path Tests (expected inputs, successful outcomes)
‚ñ° Edge Case Tests (boundary conditions, unusual inputs)
‚ñ° Error Condition Tests (invalid inputs, system failures)
‚ñ° Performance Tests (timing, throughput, resource usage)
‚ñ° Data Integrity Tests (field mapping accuracy, no data loss)
‚ñ° Recovery Tests (cleanup, rollback, error recovery)
```

**DELIVERABLE:** `test-cases.json` with detailed scenario specifications

### **TASK 2.3: Implementation Strategy**
Plan the development approach:

```markdown
**IMPLEMENTATION PHASES:**
‚ñ° Phase A: Core MCP tool integration and verification
‚ñ° Phase B: Node.js helper script development
‚ñ° Phase C: Test case implementation and validation
‚ñ° Phase D: Automated reporting and analytics
‚ñ° Phase E: Production deployment and monitoring
‚ñ° Phase F: Documentation and handover
```

**DELIVERABLE:** `implementation-strategy.md` with timeline and dependencies

---

## ‚öôÔ∏è **PHASE 3: CHUNKED EXECUTION PLAN (REQUIRED)**

### **EXECUTION PRINCIPLES:**
- **‚â§5 operations per chunk** with user confirmation between chunks
- **Evidence-based validation** after each chunk
- **Confidence scoring** for all deliverables
- **Anti-hallucination checks** at each validation point
- **File-based progress tracking** for recovery and transparency

### **CHUNK 1: MCP Tool Validation & Baseline**
```markdown
**OPERATIONS (‚â§5):**
1. **Test MCP connectivity** ‚Üí mcp_n8n_n8n_list_executions (verify access)
2. **Baseline workflow analysis** ‚Üí mcp_n8n_get_workflow(wpg9K9s8wlfofv1u)
3. **Current data assessment** ‚Üí mcp_airtable_list_records (sample current records)
4. **Document baseline** ‚Üí Save workflow structure + data patterns
5. **Confidence assessment** ‚Üí Score MCP tool reliability

**EVIDENCE REQUIRED:**
‚úÖ Execution IDs from MCP calls
‚úÖ Workflow JSON structure captured
‚úÖ Record count and field patterns documented
‚úÖ No MCP tool failures or errors

**USER CONFIRMATION**: Wait for 'PROCEED' before next chunk
```

### **CHUNK 2: Test Environment Setup**
```markdown
**OPERATIONS (‚â§5):**
1. **Create test data patterns** ‚Üí mcp_airtable_create_record (test records)
2. **Validate test webhook** ‚Üí Test webhook with known payload
3. **Verify processing flow** ‚Üí mcp_n8n_n8n_get_execution (check execution)
4. **Document test environment** ‚Üí Save test configuration
5. **Cleanup verification** ‚Üí mcp_airtable_delete_records (test cleanup)

**EVIDENCE REQUIRED:**
‚úÖ Test record IDs created and verified
‚úÖ Webhook response codes documented  
‚úÖ Execution IDs from test runs
‚úÖ Successful cleanup confirmation

**USER CONFIRMATION**: Wait for 'PROCEED' before next chunk
```

### **CHUNK 3: Core Testing Framework**
```markdown
**OPERATIONS (‚â§5):**
1. **Implement test orchestrator** ‚Üí AI agent script for MCP orchestration
2. **Create helper scripts** ‚Üí Node.js scripts for HTTP operations
3. **Build evidence collector** ‚Üí System for cross-system verification
4. **Test communication layer** ‚Üí File-based handoff between layers
5. **Validate framework** ‚Üí End-to-end test with single scenario

**EVIDENCE REQUIRED:**
‚úÖ Working orchestrator with MCP integration
‚úÖ Helper scripts execute without errors
‚úÖ Evidence files generated successfully
‚úÖ Communication layer functional

**USER CONFIRMATION**: Wait for 'PROCEED' before next chunk
```

### **CHUNK 4: Test Case Implementation**
```markdown
**OPERATIONS (‚â§5):**
1. **Implement field normalization tests** ‚Üí Mixed case field scenarios
2. **Implement boolean conversion tests** ‚Üí String ‚Üí boolean verification
3. **Implement phone strategy tests** ‚Üí International format handling
4. **Implement error condition tests** ‚Üí Invalid payload handling
5. **Validate all test cases** ‚Üí Execute full test suite

**EVIDENCE REQUIRED:**
‚úÖ All test scenarios execute successfully
‚úÖ Field mapping accuracy measured and reported
‚úÖ Boolean conversions verified in Airtable
‚úÖ Error conditions handled gracefully

**USER CONFIRMATION**: Wait for 'PROCEED' before next chunk
```

### **CHUNK 5: Automation & Reporting**
```markdown
**OPERATIONS (‚â§5):**
1. **Build automated runner** ‚Üí Single-command test execution
2. **Implement reporting system** ‚Üí JSON + human-readable reports
3. **Add confidence scoring** ‚Üí Evidence-based reliability metrics
4. **Create monitoring dashboard** ‚Üí Real-time test status
5. **Validate automation** ‚Üí Full autonomous test run

**EVIDENCE REQUIRED:**
‚úÖ Automated runner executes without manual intervention
‚úÖ Reports generated with confidence scores
‚úÖ All evidence properly collected and formatted
‚úÖ Zero fabrication or simulation detected

**USER CONFIRMATION**: Wait for 'PROCEED' before next chunk
```

---

## ‚úÖ **PHASE 4: VALIDATION PROTOCOLS (REQUIRED)**

### **VALIDATION CHECKLIST:**
```markdown
**FUNCTIONAL VALIDATION:**
‚ñ° All 8 test scenarios execute successfully
‚ñ° MCP tools integrated without errors
‚ñ° Evidence collection working across all systems
‚ñ° Confidence scoring accurate and evidence-based
‚ñ° Cleanup procedures working reliably

**PERFORMANCE VALIDATION:**
‚ñ° Test execution time within reasonable limits (<5 min full suite)
‚ñ° Resource usage acceptable (memory, CPU, network)
‚ñ° Error recovery working for all failure modes
‚ñ° Parallel testing capability demonstrated

**QUALITY VALIDATION:**
‚ñ° Field mapping accuracy >95% across all test cases
‚ñ° Boolean conversion 100% reliable
‚ñ° Phone strategy handling all international formats
‚ñ° Duplicate detection working correctly
‚ñ° No data corruption or data loss detected

**PRODUCTION READINESS:**
‚ñ° Documentation complete and accurate
‚ñ° Installation/setup procedures tested
‚ñ° Error messages clear and actionable
‚ñ° Logging and monitoring adequate
‚ñ° Backup and recovery procedures working
```

### **VALIDATION EVIDENCE REQUIREMENTS:**
- **Test Execution Logs**: Complete run with timestamps
- **MCP Tool Responses**: Actual API responses, not fabricated
- **Airtable Verification**: Record IDs that can be manually verified
- **N8N Execution Data**: Real execution IDs from workflow runs
- **Confidence Metrics**: Evidence-based scoring with rationale

---

## üö® **PHASE 5: ANTI-HALLUCINATION ENFORCEMENT (MANDATORY)**

### **MANDATORY CONFIDENCE SCORING:**
```markdown
**CONFIDENCE ASSESSMENT FRAMEWORK:**
- **100%**: All tests pass, all evidence verified, zero assumptions
- **90-99%**: Minor gaps in coverage or evidence
- **80-89%**: Some assumptions made but well-documented
- **70-79%**: Significant gaps but core functionality working
- **<70%**: Major issues, not production ready

**FORMAT REQUIRED**: "Confidence: X% - [detailed rationale based on evidence]"
```

### **EVIDENCE VERIFICATION CHECKLIST:**
```markdown
**BEFORE CLAIMING SUCCESS:**
‚ñ° MCP tool responses are real (show actual JSON responses)
‚ñ° Airtable records created (provide actual record IDs)
‚ñ° N8N executions verified (provide actual execution IDs)  
‚ñ° Webhook responses real (show actual HTTP status codes)
‚ñ° Test cleanup verified (show before/after record counts)
‚ñ° No simulation or fabrication anywhere in the system

**PROHIBITED PATTERNS:**
‚ùå Echo commands generating fake MCP responses
‚ùå Hardcoded success values without verification
‚ùå Claims of "working perfectly" without evidence
‚ùå Simulated delays or responses
‚ùå Assumptions passed off as facts
```

### **VERIFICATION PROTOCOL:**
```markdown
**FOR EVERY MAJOR CLAIM:**
1. **State the claim clearly**
2. **Provide evidence (tool output, IDs, data)**  
3. **Show verification method**
4. **Include confidence score with rationale**
5. **Document any assumptions or limitations**

**EXAMPLE GOOD PATTERN:**
"Field normalization test PASSED - Evidence: Created record recXXXXXXXXXXXXXX with email 'test@example.com' using mcp_airtable_create_record, verified fields captured 8/8 expected via mcp_airtable_get_record. Confidence: 95% - All core fields verified, edge cases need more testing."

**EXAMPLE PROHIBITED PATTERN:**  
"Field normalization working perfectly! All tests passed with 100% success rate." (No evidence, no record IDs, overconfident claim)
```

---

## üìö **CONTEXT FILES & DOCUMENTATION AVAILABLE**

### **CRITICAL REFERENCE FILES:**
- `.cursorrules/00-CRITICAL-ALWAYS.md` - Anti-hallucination protocols
- `patterns/00-field-normalization-mandatory.txt` - Field mapping requirements
- `docs/critical-platform-gotchas.md` - N8N platform issues to avoid
- `docs/reference/uysp-critical-patterns & enforcment.md` - Business logic patterns
- `tests/FAKE-PATTERN-DETECTION-REPORT.json` - What NOT to do (fake patterns)

### **MCP TOOL DOCUMENTATION:**
- Available via `mcp_n8n_tools_documentation()` for N8N tools
- Available via standard help for Airtable tools
- Context7 available for additional N8N documentation

### **EXISTING TEST EXAMPLES:**
- `tests/results/` - Previous test execution examples
- `tests/payloads/` - Known working test payloads
- Review but do NOT copy failed approaches from quarantined files

---

## üéØ **SUCCESS CRITERIA (FINAL DELIVERABLES)**

### **MUST DELIVER:**

1. **Production-Ready Testing Infrastructure**
   - Automated test execution with single command
   - All 8+ test scenarios covered with evidence
   - MCP-based verification for all claims
   - Confidence scoring for all results

2. **Complete Documentation Package**
   - Installation and setup guide
   - Test execution procedures  
   - Troubleshooting guide
   - Evidence collection protocols

3. **Validation Evidence**
   - Real MCP tool execution logs
   - Actual Airtable record IDs from tests
   - N8N execution IDs from webhook runs
   - Performance metrics and success rates

4. **Anti-Hallucination Compliance**
   - No fabricated responses or simulation
   - Evidence-based confidence scoring throughout
   - Clear documentation of limitations and assumptions
   - Verification protocols for all major claims

### **QUALITY GATES:**
- **Technical**: All tests execute successfully with real MCP tools
- **Business**: >95% field mapping accuracy achieved
- **Operational**: Complete autonomous testing capability  
- **Documentation**: Installation by fresh user possible
- **Reliability**: Error recovery and cleanup working

---

## ‚ö° **EXECUTION INSTRUCTIONS**

### **START IMMEDIATELY WITH:**
1. **Read this entire prompt carefully**
2. **Confirm MCP tool access** by testing one tool (e.g., `mcp_n8n_n8n_list_executions`)
3. **Begin Phase 1: Analysis** with current system assessment
4. **Create progress tracking file** for transparency
5. **Request user confirmation** before proceeding to implementation

### **COMMUNICATION PROTOCOL:**
- **Update progress** after each chunk completion
- **Request explicit user approval** before major implementation steps
- **Provide evidence** for all claims immediately
- **Include confidence scores** in every major deliverable
- **Document assumptions** and limitations clearly

### **REMEMBER:**
- You have **full MCP tool access** - use it extensively
- **Never simulate or fabricate** anything
- **File-based communication** between AI and Node.js layers
- **Evidence-based development** throughout
- **Chunk-based execution** with user approval gates

---

## üèÅ **FINAL MANDATE**

Build a **world-class, production-ready testing infrastructure** that leverages the proper architecture (AI agent MCP orchestration + Node.js helpers) to deliver **comprehensive, reliable, automated testing** of UYSP N8N workflows.

**Success means**: A fresh user can run a single command and get comprehensive test results with confidence scores and evidence for every claim.

**Failure means**: Any simulation, fabrication, or untestable claims in the final deliverable.

---

**Begin immediately. The UYSP system needs reliable testing infrastructure, and you have all the tools and knowledge required to deliver it.**